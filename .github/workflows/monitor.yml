name: Monitor

on:
  schedule:
    - cron: '*/2 * * * *'
  workflow_dispatch:

jobs:
  check:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Check and Notify
        env:
          EMAIL_TO: ${{ secrets.EMAIL_TO }}
          EMAIL_FROM: ${{ secrets.EMAIL_FROM }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          TARGET_USER: ${{ secrets.TARGET_USER }}
        run: |
          python3 << 'PYEOF'
          import os
          import json
          import re
          import smtplib
          import time
          import urllib.request
          from email.mime.text import MIMEText

          target_user = os.environ.get("TARGET_USER", "")
          tweet_ids = []

          # 方法1: Twitter 内嵌时间线 API
          def try_syndication():
              url = f"https://syndication.twitter.com/srv/timeline-profile/screen-name/{target_user}"
              headers = {
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                  "Referer": "https://platform.twitter.com/",
                  "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8",
              }
              try:
                  req = urllib.request.Request(url, headers=headers)
                  resp = urllib.request.urlopen(req, timeout=30)
                  html = resp.read().decode("utf-8", errors="ignore")
                  print(f"syndication 页面长度: {len(html)}")
                  matches = re.findall(r'/status/(\d{15,25})', html)
                  print(f"syndication 匹配数: {len(matches)}")
                  return matches
              except Exception as e:
                  print(f"syndication 失败: {e}")
                  return []

          # 方法2: Twitter Publish oEmbed API
          def try_publish():
              url = f"https://publish.twitter.com/oembed?url=https://twitter.com/{target_user}"
              headers = {
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
              }
              try:
                  req = urllib.request.Request(url, headers=headers)
                  resp = urllib.request.urlopen(req, timeout=30)
                  data = json.loads(resp.read().decode("utf-8"))
                  html = data.get("html", "")
                  print(f"publish API 获取成功")
                  matches = re.findall(r'/status/(\d{15,25})', html)
                  return matches
              except Exception as e:
                  print(f"publish 失败: {e}")
                  return []

          # 方法3: 使用 Nitter 替代实例
          def try_nitter():
              instances = [
                  f"https://nitter.poast.org/{target_user}",
                  f"https://nitter.privacydev.net/{target_user}",
                  f"https://nitter.net/{target_user}",
                  f"https://xcancel.com/{target_user}",
                  f"https://twiiit.com/{target_user}",
              ]
              headers = {
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
              }
              for inst_url in instances:
                  try:
                      req = urllib.request.Request(inst_url, headers=headers)
                      resp = urllib.request.urlopen(req, timeout=15)
                      html = resp.read().decode("utf-8", errors="ignore")
                      matches = re.findall(r'/status/(\d{15,25})', html)
                      if matches:
                          print(f"{inst_url} 成功，匹配数: {len(matches)}")
                          return matches
                      else:
                          print(f"{inst_url} 无匹配")
                  except Exception as e:
                      print(f"{inst_url} 失败: {e}")
              return []

          # 方法4: 使用 RSS Bridge
          def try_rssbridge():
              bridges = [
                  f"https://rss-bridge.org/bridge01/?action=display&bridge=TwitterBridge&context=By+username&u={target_user}&format=Html",
              ]
              headers = {
                  "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
              }
              for bridge_url in bridges:
                  try:
                      req = urllib.request.Request(bridge_url, headers=headers)
                      resp = urllib.request.urlopen(req, timeout=30)
                      html = resp.read().decode("utf-8", errors="ignore")
                      matches = re.findall(r'/status/(\d{15,25})', html)
                      if matches:
                          print(f"RSS Bridge 成功，匹配数: {len(matches)}")
                          return matches
                      else:
                          print(f"RSS Bridge 无匹配")
                  except Exception as e:
                      print(f"RSS Bridge 失败: {e}")
              return []

          # 依次尝试所有方法
          print("=== 尝试方法1: syndication ===")
          all_matches = try_syndication()

          if not all_matches:
              print("=== 尝试方法2: publish ===")
              all_matches = try_publish()

          if not all_matches:
              print("=== 尝试方法3: nitter ===")
              all_matches = try_nitter()

          if not all_matches:
              print("=== 尝试方法4: RSS Bridge ===")
              all_matches = try_rssbridge()

          # 去重保留前5条
          seen = []
          for tid in all_matches:
              if tid not in seen:
                  seen.append(tid)
              if len(seen) >= 5:
                  break

          tweet_ids = seen
          print(f"\n最终推文ID: {tweet_ids}")

          if not tweet_ids:
              print("所有方法都失败了")
              exit(0)

          # 读取历史
          history_file = "last_tweets.json"
          old_tweets = []
          first_run = False

          if os.path.exists(history_file):
              with open(history_file, "r") as f:
                  old_tweets = json.load(f)
          else:
              first_run = True

          print(f"上次推文ID: {old_tweets}")

          # 对比
          new_tweets = [t for t in tweet_ids if t not in old_tweets]
          should_send = first_run or len(new_tweets) > 0

          if should_send:
              links = [f"https://x.com/i/status/{tid}" for tid in (new_tweets if new_tweets else tweet_ids)]
              if first_run:
                  body = "监控已启动:\n\n" + "\n".join(links)
              else:
                  body = "检测到新内容:\n\n" + "\n".join(links)

              email_to = os.environ.get("EMAIL_TO", "")
              email_from = os.environ.get("EMAIL_FROM", "")
              email_password = os.environ.get("EMAIL_PASSWORD", "")

              if email_to and email_from and email_password:
                  try:
                      msg = MIMEText(body, "plain", "utf-8")
                      msg["Subject"] = "页面更新通知"
                      msg["From"] = email_from
                      msg["To"] = email_to

                      server = smtplib.SMTP_SSL("smtp.gmail.com", 465)
                      server.login(email_from, email_password)
                      server.sendmail(email_from, email_to, msg.as_string())
                      server.quit()
                      print("邮件已发送")
                  except Exception as e:
                      print(f"邮件发送失败: {e}")
              else:
                  print("邮箱未配置")
          else:
              print("没有新推文")

          # 保存状态
          with open(history_file, "w") as f:
              json.dump(tweet_ids, f)

          PYEOF

      - name: Save State
        if: always()
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add last_tweets.json 2>/dev/null || true
          git diff --cached --quiet || git commit -m "update state"
          git push || true
